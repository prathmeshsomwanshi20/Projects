{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361ce61e-cfc1-4d49-a604-909d605d0642",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_text = \"Artificial Intelligence (AI) is transforming numerous industries by enhancing efficiencies and creating new opportunities. From healthcare to transportation, AI applications are helping businesses optimize their processes and deliver better services. For instance, AI-driven algorithms can analyze vast amounts of data to uncover insights that humans might miss. In healthcare, AI is being used for accurate diagnostics and personalized medicine. Moreover, autonomous vehicles, powered by AI, promise to revolutionize the way we commute and transport goods. However, as AI technology advances, it also poses ethical challenges, including concerns about privacy and job displacement. Society must navigate these challenges thoughtfully to leverage AI's full potential while minimizing risks. Overall, the impact of AI on the modern world is profound and multifaceted, making it a pivotal part of future innovations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae565a-382e-4023-9469-0e4cc727e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8112f775-0bc1-4492-91cb-df515a6744ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"artificial intelligence (ai) is transforming numerous industries by enhancing efficiencies and creating new opportunities. from healthcare to transportation, ai applications are helping businesses optimize their processes and deliver better services. for instance, ai-driven algorithms can analyze vast amounts of data to uncover insights that humans might miss. in healthcare, ai is being used for accurate diagnostics and personalized medicine. moreover, autonomous vehicles, powered by ai, promise to revolutionize the way we commute and transport goods. however, as ai technology advances, it also poses ethical challenges, including concerns about privacy and job displacement. society must navigate these challenges thoughtfully to leverage ai's full potential while minimizing risks. overall, the impact of ai on the modern world is profound and multifaceted, making it a pivotal part of future innovations.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_text = actual_text.lower()\n",
    "actual_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1cd06f-7491-4873-ba42-d6d8494e436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artificial intelligence ai is transforming numerous industries by enhancing efficiencies and creating new opportunities from healthcare to transportation ai applications are helping businesses optimize their processes and deliver better services for instance ai driven algorithms can analyze vast amounts of data to uncover insights that humans might miss in healthcare ai is being used for accurate diagnostics and personalized medicine moreover autonomous vehicles powered by ai promise to revolutionize the way we commute and transport goods however as ai technology advances it also poses ethical challenges including concerns about privacy and job displacement society must navigate these challenges thoughtfully to leverage ai s full potential while minimizing risks overall the impact of ai on the modern world is profound and multifaceted making it a pivotal part of future innovations '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = re.sub('[^a-zA-Z]', ' ', actual_text) # this line says if any character is not an alphabet then replace it with the space.\n",
    "clean_text = re.sub('\\s+', ' ', clean_text) # Now due to your above work there may be generated many white spaces so it aggregates it and make it a single white space.\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d7bac-d011-46c1-82f8-35528e2373d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = nltk.sent_tokenize(actual_text) # Now basically using the sent_tokenize functionality of nltk we are creating sentences as distinct objects from the text and nltk already has pre defined models that can logicall set the boundaries of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede7fd5b-baa8-4bba-9fb3-2bc552034e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') # Here we are downloading all the stopwords at once. Stop words are the ones which are less important like and, the or this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083660e2-9064-4619-a14c-1957548660c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english') # import all the stop words from english\n",
    "\n",
    "word_frequencies = {} # just created a dictionary that will store words and their frequency\n",
    "for word in nltk.word_tokenize(clean_text): # split the clean text into individual words or tokens\n",
    "    if word not in stopwords:\n",
    "        if word not in word_frequencies:\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce9fe23-5242-41ff-a9d0-846c9dc5bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9631341-eca0-47d2-906b-1e3f59e83465",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "\n",
    "for sentence in sentence_list:\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        if word in word_frequencies and len(sentence.split(' ')) < 30: # here we check if the sentence contain a significant work from earlier declared dictionary and then \n",
    "            # if the sentence has less than 30 occurences of that word then accept it.\n",
    "            if sentence not in sentence_scores:\n",
    "                sentence_scores[sentence] = word_frequencies[word]\n",
    "            else:\n",
    "                sentence_scores[sentence] += word_frequencies[word]\n",
    "# here in above if else we are just including each sentence in the scores named dictionary and and keeping the count of frequencies of all words that are present in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87dce48c-5276-45e5-ad67-ff572048f270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artificial': 0.125,\n",
       " 'intelligence': 0.125,\n",
       " 'ai': 1.0,\n",
       " 'transforming': 0.125,\n",
       " 'numerous': 0.125,\n",
       " 'industries': 0.125,\n",
       " 'enhancing': 0.125,\n",
       " 'efficiencies': 0.125,\n",
       " 'creating': 0.125,\n",
       " 'new': 0.125,\n",
       " 'opportunities': 0.125,\n",
       " 'healthcare': 0.25,\n",
       " 'transportation': 0.125,\n",
       " 'applications': 0.125,\n",
       " 'helping': 0.125,\n",
       " 'businesses': 0.125,\n",
       " 'optimize': 0.125,\n",
       " 'processes': 0.125,\n",
       " 'deliver': 0.125,\n",
       " 'better': 0.125,\n",
       " 'services': 0.125,\n",
       " 'instance': 0.125,\n",
       " 'driven': 0.125,\n",
       " 'algorithms': 0.125,\n",
       " 'analyze': 0.125,\n",
       " 'vast': 0.125,\n",
       " 'amounts': 0.125,\n",
       " 'data': 0.125,\n",
       " 'uncover': 0.125,\n",
       " 'insights': 0.125,\n",
       " 'humans': 0.125,\n",
       " 'might': 0.125,\n",
       " 'miss': 0.125,\n",
       " 'used': 0.125,\n",
       " 'accurate': 0.125,\n",
       " 'diagnostics': 0.125,\n",
       " 'personalized': 0.125,\n",
       " 'medicine': 0.125,\n",
       " 'moreover': 0.125,\n",
       " 'autonomous': 0.125,\n",
       " 'vehicles': 0.125,\n",
       " 'powered': 0.125,\n",
       " 'promise': 0.125,\n",
       " 'revolutionize': 0.125,\n",
       " 'way': 0.125,\n",
       " 'commute': 0.125,\n",
       " 'transport': 0.125,\n",
       " 'goods': 0.125,\n",
       " 'however': 0.125,\n",
       " 'technology': 0.125,\n",
       " 'advances': 0.125,\n",
       " 'also': 0.125,\n",
       " 'poses': 0.125,\n",
       " 'ethical': 0.125,\n",
       " 'challenges': 0.25,\n",
       " 'including': 0.125,\n",
       " 'concerns': 0.125,\n",
       " 'privacy': 0.125,\n",
       " 'job': 0.125,\n",
       " 'displacement': 0.125,\n",
       " 'society': 0.125,\n",
       " 'must': 0.125,\n",
       " 'navigate': 0.125,\n",
       " 'thoughtfully': 0.125,\n",
       " 'leverage': 0.125,\n",
       " 'full': 0.125,\n",
       " 'potential': 0.125,\n",
       " 'minimizing': 0.125,\n",
       " 'risks': 0.125,\n",
       " 'overall': 0.125,\n",
       " 'impact': 0.125,\n",
       " 'modern': 0.125,\n",
       " 'world': 0.125,\n",
       " 'profound': 0.125,\n",
       " 'multifaceted': 0.125,\n",
       " 'making': 0.125,\n",
       " 'pivotal': 0.125,\n",
       " 'part': 0.125,\n",
       " 'future': 0.125,\n",
       " 'innovations': 0.125}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff3be9f2-4dca-490f-866b-20d14d84952e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artificial intelligence (ai) is transforming numerous industries by enhancing efficiencies and creating new opportunities.': 2.25,\n",
       " 'from healthcare to transportation, ai applications are helping businesses optimize their processes and deliver better services.': 2.375,\n",
       " 'for instance, ai-driven algorithms can analyze vast amounts of data to uncover insights that humans might miss.': 1.375,\n",
       " 'in healthcare, ai is being used for accurate diagnostics and personalized medicine.': 1.875,\n",
       " 'moreover, autonomous vehicles, powered by ai, promise to revolutionize the way we commute and transport goods.': 2.25,\n",
       " 'however, as ai technology advances, it also poses ethical challenges, including concerns about privacy and job displacement.': 2.625,\n",
       " \"society must navigate these challenges thoughtfully to leverage ai's full potential while minimizing risks.\": 2.375,\n",
       " 'overall, the impact of ai on the modern world is profound and multifaceted, making it a pivotal part of future innovations.': 2.375}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e31ede0-ed49-497a-93d8-c0e5d424c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "however, as ai technology advances, it also poses ethical challenges, including concerns about privacy and job displacement. from healthcare to transportation, ai applications are helping businesses optimize their processes and deliver better services. society must navigate these challenges thoughtfully to leverage ai's full potential while minimizing risks. overall, the impact of ai on the modern world is profound and multifaceted, making it a pivotal part of future innovations. artificial intelligence (ai) is transforming numerous industries by enhancing efficiencies and creating new opportunities.\n"
     ]
    }
   ],
   "source": [
    "import heapq # using heapq functionality you can say the element with highest score will be in the front and then 2nd highest second and that's all.\n",
    "summary = heapq.nlargest(5, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "print(\" \".join(summary))\n",
    "# just extract the top five sentences based on their scores and then join them in a single string. nlargest method gives 5 largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a263be61-4e38-4aa9-884d-3cff0d4e6f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting cmudict (from textstat)\n",
      "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from textstat) (68.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from cmudict->textstat) (7.0.1)\n",
      "Collecting importlib-resources>=5 (from cmudict->textstat)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from importlib-metadata>=5->cmudict->textstat) (3.17.0)\n",
      "Downloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.3 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 61.4/105.3 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 105.3/105.3 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
      "   ---------------------------------------- 0.0/939.4 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 153.6/939.4 kB 2.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 204.8/939.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 266.2/939.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 327.7/939.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 460.8/939.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 522.2/939.4 kB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 645.1/939.4 kB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 727.0/939.4 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 819.2/939.4 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  931.8/939.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 939.4/939.4 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/2.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.9/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.1 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.9/2.1 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.1 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: pyphen, importlib-resources, cmudict, textstat\n",
      "Successfully installed cmudict-1.0.32 importlib-resources-6.5.2 pyphen-0.17.2 textstat-0.7.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8628c01-c1c6-4e73-b2f8-03f68c4a2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flesch-Kincaid Grade Level: 15.4\n",
      "This text is better for college-level readers.\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "# Calculate readability\n",
    "readability_score = textstat.flesch_kincaid_grade(actual_text)\n",
    "\n",
    "print(f\"Flesch-Kincaid Grade Level: {readability_score}\")\n",
    "if readability_score < 6:\n",
    "    print(\"This text is suitable for a lower reading level.\")\n",
    "elif 6 <= readability_score < 12:\n",
    "    print(\"This text is suitable for middle school to high school students.\")\n",
    "else:\n",
    "    print(\"This text is better for college-level readers.\")\n",
    "\n",
    "#Flesch-Kincaid Grade Level: Basically it is a US based technique that is used to find the complexity in text they have their own formula of finding complexity using words, syllabis and all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29e029b-2592-4a5c-82ca-77ef82f04160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spaCy is a popular open-source library for advanced natural language processing (NLP) in Python.\n",
    "#1. For high speed data access and manipulation\n",
    "#2. Pre-trained models\n",
    "#3. Easy Integration.\n",
    "#Load the model: Load the English language model en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794e417-c59c-4188-b4e2-43736de4feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Named Entity Recognition (NER) is a subtask of Natural Language Processing (NLP) that involves locating and classifying named entities in text into predefined categories, \n",
    "#such as persons, organizations, locations, dates, and more. Works by tokenization, POS tagging and then entity recognition.\n",
    "#Entity: Apple Inc., Label: ORG\n",
    "#Entity: New York City, Label: GPE\n",
    "#Entity: Tim Cook, Label: PERSON\n",
    "#Entity: Apple, Label: ORG\n",
    "#Entity: September 25, 2023, Label: DATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
